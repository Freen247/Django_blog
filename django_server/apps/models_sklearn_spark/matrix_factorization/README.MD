## 矩阵分解算法
> 数据集使用电影数据集[官网下载](http://files.grouplens.org/datasets/movielens/ml-1m.zip)

推荐算法具有非常多的应用场景和商业价值，因此对推荐算法值得好好研究。推荐算法种类很多，但是目前应用最广泛的应该是协同过滤类别的推荐算法，本文就对协同过滤类别的推荐算法做一个概括总结，后续也会对一些典型的协同过滤推荐算法做原理总结。

我们常见的矩阵矩阵分解有`BPR、SVD（funkSVD）、ALS、NMF、WRMF`。

### BPR

### SVD（funkSVD）

说道矩阵分解，我们首先想到的就是奇异值分解SVD。在奇异值分解(SVD)原理与在降维中的应用中，我们对SVD原理做了总结。如果大家对SVD不熟悉的话，可以翻看该文。

此时可以将这个用户物品对应的m×n矩阵M进行SVD分解，并通过选择部分较大的一些奇异值来同时进行降维，也就是说矩阵M此时分解为：
M(m×n)=U(m×k)Σ(k×k)V(k×n)

　　　　其中k是矩阵M中较大的部分奇异值的个数，一般会远远的小于用户数和物品树。如果我们要预测第i个用户对第j个物品的评分mij,则只需要计算uTiΣvj即可。通过这种方法，我们可以将评分表里面所有没有评分的位置得到一个预测评分。通过找到最高的若干个评分对应的物品推荐给用户。

　　　　可以看出这种方法简单直接，似乎很有吸引力。但是有一个很大的问题我们忽略了，就是SVD分解要求矩阵是稠密的，也就是说矩阵的所有位置不能有空白。有空白时我们的M是没法直接去SVD分解的。大家会说，如果这个矩阵是稠密的，那不就是说我们都已经找到所有用户物品的评分了嘛，那还要SVD干嘛! 的确，这是一个问题，传统SVD采用的方法是对评分矩阵中的缺失值进行简单的补全，比如用全局平均值或者用用户物品平均值补全，得到补全后的矩阵。接着可以用SVD分解并降维。

　　　　虽然有了上面的补全策略，我们的传统SVD在推荐算法上还是较难使用。因为我们的用户数和物品一般都是超级大，随便就成千上万了。这么大一个矩阵做SVD分解是非常耗时的。